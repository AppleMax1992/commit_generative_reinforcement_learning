{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wwj39FCi8VW8"
   },
   "source": [
    "# Tune GPT2 to generate controlled sentiment reviews\n",
    "> Optimise GPT2 to produce IMDB movie reviews with controlled sentiment using a BERT sentiment classifier for rewards.\n",
    "\n",
    "**WARNING:** We often experienced loss spikes in this examples which caused model training to fail or slow down. There is a [GitHub issue](https://github.com/lvwerra/trl/issues/101) to track the issue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xSoKuUBl8VW9"
   },
   "source": [
    "<div style=\"text-align: center\">\n",
    "<img src='https://huggingface.co/datasets/trl-internal-testing/example-images/resolve/main/images/gpt2-ctrl-training-setup.png' width='600'>\n",
    "<p style=\"text-align: center;\"> <b>Figure:</b> Experiment setup to tune GPT2. The yellow arrows are outside the scope of this notebook, but the trained models are available through Hugging Face. </p>\n",
    "</div>\n",
    "\n",
    "\n",
    "The experiment setup is very similar to the positive sentiment notebook. However, in this notebook we fine-tune GPT2 (small) to generate **controlled** movie reviews based on the IMDB dataset. The model gets the target sentiment and 5 tokens from a real review and is tasked to produce continuations with the targeted sentiment. The reward for the continuations is calculated with the logits of a BERT sentiment classifier. That reward is then used for PPO training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yqeHaF9A8VW-"
   },
   "source": [
    "## Setup experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qyK6pOWq8VW-"
   },
   "source": [
    "### Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2026-01-02T15:46:05.217061Z",
     "iopub.status.busy": "2026-01-02T15:46:05.216757Z",
     "iopub.status.idle": "2026-01-02T15:46:05.220476Z",
     "shell.execute_reply": "2026-01-02T15:46:05.219847Z",
     "shell.execute_reply.started": "2026-01-02T15:46:05.217028Z"
    },
    "id": "Zd402c8w8bc-",
    "outputId": "69d91bc2-8cc6-4c1a-8f2d-195780d95ba0"
   },
   "outputs": [],
   "source": [
    "# !pip install trl==0.11.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T15:46:05.221509Z",
     "iopub.status.busy": "2026-01-02T15:46:05.221234Z",
     "iopub.status.idle": "2026-01-02T15:46:05.243376Z",
     "shell.execute_reply": "2026-01-02T15:46:05.242702Z",
     "shell.execute_reply.started": "2026-01-02T15:46:05.221481Z"
    },
    "id": "_agwXaV58VW-"
   },
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T15:46:05.324930Z",
     "iopub.status.busy": "2026-01-02T15:46:05.324533Z",
     "iopub.status.idle": "2026-01-02T15:46:10.840405Z",
     "shell.execute_reply": "2026-01-02T15:46:10.839873Z",
     "shell.execute_reply.started": "2026-01-02T15:46:05.324898Z"
    },
    "id": "nKhgHb518VW_"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import wandb\n",
    "import time\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict\n",
    "from random import choices\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tqdm.pandas()\n",
    "import sys\n",
    "sys.path.append('/root/autodl-tmp/commit_generative_reinforcement_learning')\n",
    "# from datasets import load_dataset\n",
    "\n",
    "from transformers import AutoTokenizer, pipeline, AutoModelForCausalLM\n",
    "\n",
    "from trl import (\n",
    "    PPOTrainer,\n",
    "    PPOConfig,\n",
    "    AutoModelForCausalLMWithValueHead,\n",
    "    create_reference_model,\n",
    ")\n",
    "from trl import AutoModelForSeq2SeqLMWithValueHead\n",
    "# from trl.experimental.ppo import PPOTrainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "diQgtTJL8VW_"
   },
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2026-01-02T15:46:10.841539Z",
     "iopub.status.busy": "2026-01-02T15:46:10.841199Z",
     "iopub.status.idle": "2026-01-02T15:46:10.844867Z",
     "shell.execute_reply": "2026-01-02T15:46:10.844445Z",
     "shell.execute_reply.started": "2026-01-02T15:46:10.841522Z"
    },
    "id": "EiunZ7YX8VW_",
    "outputId": "9a0ffd11-7d08-4120-ab88-3afc4c082506"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/autodl-tmp/commit_generative_reinforcement_learning/trl/trainer/ppo_config.py:207: FutureWarning: `PPOConfig` is deprecated and will be removed in the future. Please use `PPOv2Config` with `PPOv2Trainer` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "commit_pipe_kwargs = {\"top_k\": None, \"function_to_apply\": \"none\"}\n",
    "\n",
    "config = PPOConfig(\n",
    "    model_name=\"./codet5-sft-commit\",\n",
    "    steps=51200,\n",
    "    learning_rate=1.41e-5,\n",
    "    remove_unused_columns=False,\n",
    "    log_with=\"wandb\",\n",
    "    batch_size=32,\n",
    "    mini_batch_size=32,\n",
    ")\n",
    "\n",
    "txt_in_len = 1000\n",
    "txt_out_len = 128\n",
    "seed = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T15:46:10.845561Z",
     "iopub.status.busy": "2026-01-02T15:46:10.845422Z",
     "iopub.status.idle": "2026-01-02T15:46:10.847627Z",
     "shell.execute_reply": "2026-01-02T15:46:10.847239Z",
     "shell.execute_reply.started": "2026-01-02T15:46:10.845547Z"
    },
    "id": "WsRGwd1h8VXA"
   },
   "outputs": [],
   "source": [
    "CSV_PATH = \"/root/autodl-tmp/CommitFit/dataset/Ghadhab/dataset.csv\"\n",
    "DIFF_COL = \"diffs\"\n",
    "LABEL_COL = \"labels\"   # 如果后面不用 control token，可以不用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NHQgPOug8VXA"
   },
   "source": [
    "You can see that we load a GPT2 model called `gpt2_imdb`. This model was additionally fine-tuned on the IMDB dataset for 1 epoch with the huggingface [script](https://github.com/huggingface/transformers/blob/master/examples/run_language_modeling.py) (no special settings). The other parameters are mostly taken from the original paper [\"Fine-Tuning Language Models from Human Preferences\"](\n",
    "https://huggingface.co/papers/1909.08593). This model as well as the BERT model is available in the Huggingface model zoo [here](https://huggingface.co/models). The following code should automatically download the models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P5FyJVLl8VXA"
   },
   "source": [
    "## Load data and models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YHyp8PVt8VXB"
   },
   "source": [
    "### Load pre-trained GPT2 language models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MChMIKms8VXB"
   },
   "source": [
    "We load the GPT2 model with a value head and the tokenizer. We load the model twice; the first model is optimized while the second model serves as a reference to calculate the KL-divergence from the starting point. This serves as an additional reward signal in the PPO training to make sure the optimized model does not deviate too much from the original language model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 373,
     "referenced_widgets": [
      "65894a9b784149ef86475d11bf73b8aa",
      "e71bc8d668ab42778a533cdb23100684",
      "95717658f85a4029bb2a3b19acc0abab",
      "4461f020dc3a47f293450171ee0ea85b",
      "5ddd59e3ac6a49b3803af0dd7ee550e7",
      "86f7c09351dd4ea48ab29c302dc92b96",
      "66055024841d4158b60bdfd4945a4c88",
      "3e6e5d254a794b528dd8821a9f917a72",
      "76a3259150b84ded834fab84e826a027",
      "345e2bfdde8143458c997669717e70d3",
      "7c8d3a71da3949ea89d477684979c7fc",
      "79a6286fb73e4313bc09ad5b8376e763",
      "21c708d78411425eae4ec1ec63600f4b",
      "7b77b02c6708482d86a42bca67f8393a",
      "826c3c2d4dd64898a52db84871c53e37",
      "9c64d4596ac947a48243a832e00dde49",
      "452f552b1d0d4c179ab326e59d75014a",
      "4432a08caf1b43a69f8993516f8feb45",
      "7c220fa25b374b2599dfe046ddc37d89",
      "7fc9cd6b47ed4aba95b04cc5fe523015",
      "25dbb9dab3be451fbae095e34fcad18e",
      "a77e5075ec554c2d8cb462a0666e5108",
      "2c519f9d73084e45a55a78fdb9be227f",
      "78c65b2cb08c4c1ab48327e193cfb653",
      "ca1a60dbf5fd41edb4a2374927d59290",
      "2b42cae8dc96472bb89d123cd1234851",
      "58c84b72a67c4aebb7c5b7f988bf21d7",
      "a5133225944242ea8566decf4169a7ca",
      "79f9f2026d734ea9954c6e1e44c0079b",
      "7441a59afd9e410087c6a2e3afb09a89",
      "53cd92f3da624214b64ff0c9bf59ccda",
      "c155ccede0584d93aff0594c0a0996a8",
      "16ac7fa6c9a74162b5a7efd5acd4217a",
      "c7655b1f82f04722965fbb2a5a7386da",
      "2162d9b7274d4e938b7f2df5e6baf8fc",
      "46ef30bb565d4d3bba56dce1713dd450",
      "5d95e970ccc540388a8c3dd5e91664a4",
      "a14dcdd1868b4ad1853d7b41e91f0c77",
      "fa82928ec98d4ffc9977ae223303a85b",
      "436088a1cc614371bcca801f4802ee37",
      "b03f66aa0e1648e5aaae9e5abd560b16",
      "bc9ebe59c8eb413aa0fe0db169ca69ac",
      "9347c2fd53ba47a2b8b86043ba529d23",
      "4e6dd48281fb4ce58f49bee4808e4059",
      "03567660a91f4ac78999f921b609e242",
      "1fa1baf7df744d6b8e9e5d7fabc67345",
      "4cbc90a5ed1b4e5da61054f13b699053",
      "24b1a89895b54e99b8fbcdcfedc59166",
      "b78d2949b2964ae29757595d79a3d256",
      "b4987dde895e461fa78c76ef75dd49c8",
      "b90a41b123cc4365961d5fd1e55bee39",
      "996ce9665a0e4e619bcee99f4158bf2b",
      "997800455e424581b6bb46ef9d2478d9",
      "f6ec84261084479fb68635213a721c1f",
      "458e6f95a81140408755a0934bcc6c49",
      "50a121fd39314fb0b1a52d12d059c8a7",
      "88756c33f9e445cb84b54668e86f4895",
      "ee179ae75ece44b28ef899851f951188",
      "af795f97c4374b3f9f9ed5a983b2305b",
      "e83378f641b644c49b128d7ed46a854d",
      "fa3684b160b040118693005150836479",
      "d851ad7dd13c4d20bb82caa73bd85122",
      "24890c5b241048bd80a9de9f4a8f6a71",
      "5d9d32fbc9694614b49f4f2aff55413e",
      "9872eba8f2324f2ba022cb826661000c",
      "0698bcc01ea147218f0835df73fe403d",
      "705a89f44c6f4aa0b8e3a803ce1774a1",
      "e9bf560ab9594085af461375b0183700",
      "4a58ad2f82c04415a6ef770190586b28",
      "bc4d36c1d6014aaebcf5e7eb83dcebe5",
      "89a91db4fbec4f00991dae0e257f7145",
      "3b6913bfbea44634ab179ffa15e914dc",
      "fd482ccba50147888af089976c28b715",
      "bc3f85935c9040faafbb0c0bdc7a7923",
      "cbda542d0ba6494eb8a91eb685b066bf",
      "18bcf0683f134636b2d062e1d8e92dca",
      "76f7e8478f2e4e25a9a60735cd174039"
     ]
    },
    "execution": {
     "iopub.execute_input": "2026-01-02T15:46:10.848225Z",
     "iopub.status.busy": "2026-01-02T15:46:10.848089Z",
     "iopub.status.idle": "2026-01-02T15:46:11.319926Z",
     "shell.execute_reply": "2026-01-02T15:46:11.319285Z",
     "shell.execute_reply.started": "2026-01-02T15:46:10.848212Z"
    },
    "id": "PVK28idZ8VXB",
    "outputId": "aab3b514-e2fd-4c4b-fcfd-c2cbe94b64b9"
   },
   "outputs": [],
   "source": [
    "policy_name = config.model_name\n",
    "tokenizer = AutoTokenizer.from_pretrained(policy_name)\n",
    "\n",
    "# 1) policy / ref policy: Seq2Seq + value head\n",
    "policy = AutoModelForSeq2SeqLMWithValueHead.from_pretrained(policy_name)\n",
    "ref_policy = AutoModelForSeq2SeqLMWithValueHead.from_pretrained(policy_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2026-01-02T15:46:11.321238Z",
     "iopub.status.busy": "2026-01-02T15:46:11.321074Z",
     "iopub.status.idle": "2026-01-02T15:46:11.324350Z",
     "shell.execute_reply": "2026-01-02T15:46:11.323820Z",
     "shell.execute_reply.started": "2026-01-02T15:46:11.321222Z"
    },
    "id": "T4SdVCA1Elc0",
    "outputId": "5992ef2f-7b98-416c-a496-2b81ab8765b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eos_token_id: 2\n",
      "pad_token_id: 0\n"
     ]
    }
   ],
   "source": [
    "# 确保 eos_token_id 是正数\n",
    "print(\"eos_token_id:\", tokenizer.eos_token_id)\n",
    "print(\"pad_token_id:\", tokenizer.pad_token_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2HcNaPa38VXC"
   },
   "source": [
    "### Load IMDB dataset\n",
    "The IMDB dataset contains 50k movie review annotated with \"positive\"/\"negative\" feedback indicating the sentiment.  We load the IMDB dataset into a DataFrame and filter for comments that are at least 500 characters long and take the first 1000 characters of each comment. The first filter we apply to avoid comments that are less than `txt_in_len` token long and the second to avoid tokenizing way more text than we actually need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T15:46:11.324901Z",
     "iopub.status.busy": "2026-01-02T15:46:11.324763Z",
     "iopub.status.idle": "2026-01-02T15:46:13.200290Z",
     "shell.execute_reply": "2026-01-02T15:46:13.199741Z",
     "shell.execute_reply.started": "2026-01-02T15:46:11.324888Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e1e69aeb36b418086722237293f7d3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1246 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74135e3aaf684120aac2c62f1fb31bf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1246 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['user', 'repo', 'commit', 'labels', 'msgs', 'diffs', 'feature', 'input_ids', 'query'],\n",
      "    num_rows: 1246\n",
      "})\n",
      "{'input_ids': tensor([    1,  8496,   855,   326,  3751,   981,   471,  1045,  5678,   316,\n",
      "        15145,  2653,    30,   203,  5413,  1493,  6845,   279,    19,  4816,\n",
      "           19,  5254,    19,  6290,    19,  3341,    19,    70, 29017,  7277,\n",
      "           19,  4327,  3567,    19,  4327,    19,  2159,    19,  7025,    19,\n",
      "         2276,    18,  6290,   324,    19,  4816,    19,  5254,    19,  6290,\n",
      "           19,  3341,    19,    70, 29017,  7277,    19,  4327,  3567,    19,\n",
      "         4327,    19,  2159,    19,  7025,    19,  2276,    18,  6290,   203,\n",
      "         2704,   585,  1965,  2130, 22087,   203,  1615,   374, 17877,   838,\n",
      "           72,  3461,  3657,  9452,    71,   203,  6062,   342,  5206,    19,\n",
      "         2011,   203,  9904,    15,   324,    19,  4816,    19,  5254,    19,\n",
      "         6290,    19,  3341,    19,    70, 29017,  7277,    19,  4327,  3567,\n",
      "           19,  4327,    19,  2159,    19,  7025,    19,  2276,    18,  6290,\n",
      "          203, 30989,   300,    20,    16,    20,   397,    21,    16,  3600,\n",
      "        22175,   203,    15,  5610,  2358,    18,    70, 29017,  7277,    18,\n",
      "         4327,  3567,    18,  4327,    18,  2159,    18,  7025,    31,   203,\n",
      "           15,   203,    15,  5666,  2252,    18,  1367,    18,   863,    31,\n",
      "          203,    15,   203,    15,  5666,  2358,    18,    92, 24109,    18,\n",
      "        11482,    18,    45,    53,    31,   203,    15,   203,    15,   482,\n",
      "          667,  9705,   203,    15,    95,   203,    15,   202,   482,   225,\n",
      "          203,  9051,    30,     2]), 'query': '<s>Please read the following code and write comments in natural language:\\ndiff --git a/src/main/java/org/buddycloud/channelserver/channel/node/configuration/Helper.java b/src/main/java/org/buddycloud/channelserver/channel/node/configuration/Helper.java\\nnew file mode 100644\\nindex 00000000..d141942c\\n--- /dev/null\\n+++ b/src/main/java/org/buddycloud/channelserver/channel/node/configuration/Helper.java\\n@@ -0,0 +1,15 @@\\n+package org.buddycloud.channelserver.channel.node.configuration;\\n+\\n+import java.util.Map;\\n+\\n+import org.xmpp.packet.IQ;\\n+\\n+public class Helper\\n+{\\n+\\tpublic \\nComments:</s>'}\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# =========================\n",
    "# 1) 读 CSV\n",
    "# =========================\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "df[DIFF_COL] = df[DIFF_COL].fillna(\"\")\n",
    "\n",
    "full_dataset = Dataset.from_pandas(df, preserve_index=False)\n",
    "\n",
    "# =========================\n",
    "# 2) 划分 70 / 15 / 15\n",
    "# =========================\n",
    "first_split = full_dataset.train_test_split(test_size=0.3, seed=42)\n",
    "train_dataset = first_split[\"train\"]     # ✅ 只用这个\n",
    "tmp_dataset = first_split[\"test\"]\n",
    "\n",
    "second_split = tmp_dataset.train_test_split(test_size=0.5, seed=42)\n",
    "valid_dataset = second_split[\"test\"]\n",
    "test_dataset = second_split[\"train\"]\n",
    "\n",
    "ds_splits = DatasetDict({\n",
    "    \"train\": train_dataset,\n",
    "    \"valid\": valid_dataset,\n",
    "    \"test\":  test_dataset,\n",
    "})\n",
    "\n",
    "# =========================\n",
    "# 3) 构造 prompt（与你原逻辑一致）\n",
    "# =========================\n",
    "def build_query(diff, max_chars=500):\n",
    "    return (\n",
    "        \"Please read the following code and write comments in natural language:\\n\"\n",
    "        + diff[:max_chars]\n",
    "        + \"\\nComments:\"\n",
    "    )\n",
    "\n",
    "# =========================\n",
    "# 4) 只处理 train split\n",
    "# =========================\n",
    "train_ds = ds_splits[\"train\"]\n",
    "\n",
    "train_ds = train_ds.map(\n",
    "    lambda x: {\n",
    "        \"input_ids\": tokenizer.encode(\n",
    "            build_query(x[DIFF_COL]),\n",
    "            truncation=True,\n",
    "            max_length=txt_in_len,\n",
    "        )\n",
    "    },\n",
    "    batched=False,\n",
    ")\n",
    "\n",
    "train_ds = train_ds.map(\n",
    "    lambda x: {\n",
    "        \"query\": tokenizer.decode(x[\"input_ids\"], skip_special_tokens=False)\n",
    "    },\n",
    "    batched=False,\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# 5) 设置 PyTorch 格式\n",
    "# =========================\n",
    "train_ds.set_format(\n",
    "    type=\"torch\",\n",
    "    columns=[\"input_ids\", \"query\"],  # ✅ 加上 query\n",
    ")\n",
    "\n",
    "print(train_ds)\n",
    "print(train_ds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T15:46:13.200986Z",
     "iopub.status.busy": "2026-01-02T15:46:13.200824Z",
     "iopub.status.idle": "2026-01-02T15:46:13.205852Z",
     "shell.execute_reply": "2026-01-02T15:46:13.205348Z",
     "shell.execute_reply.started": "2026-01-02T15:46:13.200971Z"
    },
    "id": "TV4xVYeX8VXC"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column(['<s>Please read the following code and write comments in natural language:\\ndiff --git a/src/main/java/org/buddycloud/channelserver/channel/node/configuration/Helper.java b/src/main/java/org/buddycloud/channelserver/channel/node/configuration/Helper.java\\nnew file mode 100644\\nindex 00000000..d141942c\\n--- /dev/null\\n+++ b/src/main/java/org/buddycloud/channelserver/channel/node/configuration/Helper.java\\n@@ -0,0 +1,15 @@\\n+package org.buddycloud.channelserver.channel.node.configuration;\\n+\\n+import java.util.Map;\\n+\\n+import org.xmpp.packet.IQ;\\n+\\n+public class Helper\\n+{\\n+\\tpublic \\nComments:</s>', '<s>Please read the following code and write comments in natural language:\\ndiff --git a/src/libvaladoc/importer/girdocumentationimporter.vala b/src/libvaladoc/importer/girdocumentationimporter.vala\\nindex 4186c27..9984dd5 100644\\n--- a/src/libvaladoc/importer/girdocumentationimporter.vala\\n+++ b/src/libvaladoc/importer/girdocumentationimporter.vala\\n@@ -511,8 +511,11 @@ public class Valadoc.Importer.GirDocumentationImporter : DocumentationImporter {\\n \\t\\t}\\n \\n+\\t\\tbool is_type_struct = (reader.get_attribute (\"glib:is-gtype-struct-for\") != null);\\n \\t\\tnext ();\\n \\n \\t\\tApi.GirSourceCo\\nComments:</s>', '<s>Please read the following code and write comments in natural language:\\ndiff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/master/AssignmentManager.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/master/AssignmentManager.java\\nindex 87433d3006..66edd66dd6 100644\\n--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/master/AssignmentManager.java\\n+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/master/AssignmentManager.java\\n@@ -459,8 +459,8 @@ public class AssignmentManager extends ZooKeeperListener {\\n \\n     // Scan hbase:meta to build\\nComments:</s>', '<s>Please read the following code and write comments in natural language:\\ndiff --git a/rxjava-contrib/rxjava-computation-expressions/src/test/java/rx/operators/OperationConditionalsTest.java b/rxjava-contrib/rxjava-computation-expressions/src/test/java/rx/operators/OperationConditionalsTest.java\\nindex f6c4f09a..44bb0c02 100644\\n--- a/rxjava-contrib/rxjava-computation-expressions/src/test/java/rx/operators/OperationConditionalsTest.java\\n+++ b/rxjava-contrib/rxjava-computation-expressions/src/test/java/rx/operators/OperationConditionalsTest.java\\n@@ -16,4 +16,5 @@\\n packag\\nComments:</s>', '<s>Please read the following code and write comments in natural language:\\ndiff --git a/codegen/valaccodeattribute.vala b/codegen/valaccodeattribute.vala\\nindex 82a74f7c3..05745df0c 100644\\n--- a/codegen/valaccodeattribute.vala\\n+++ b/codegen/valaccodeattribute.vala\\n@@ -469,7 +469,34 @@ public class Vala.CCodeAttribute : AttributeCache {\\n \\t}\\n \\n-\\tpublic bool array_length { get; private set; }\\n+\\tpublic bool array_length {\\n+\\t\\tget {\\n+\\t\\t\\tif (_array_length == null) {\\n+\\t\\t\\t\\tif (node.get_attribute (\"NoArrayLength\") != null) {\\n+\\t\\t\\t\\t\\t// deprecated\\n+\\t\\t\\t\\t\\t_array_length = false;\\n+\\t\\t\\t\\t}\\nComments:</s>'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds['query']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qH9CnikC8VXC"
   },
   "source": [
    "### Tokenize IMDB reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4r01MBI78VXC"
   },
   "source": [
    "We tokenize all IMDB in advance to avoid tokenizing twice. In the first step we encode the queries and slice the first `txt_in_len` tokens. In a second step we decode these tokens back to text for later display."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "d826c1efbdf2423e853a3b5844f5a979",
      "b086a549590a4215bda97d750b65235e",
      "2065e1489aef4367b2adc4615dabdcaa",
      "7c74b8eb81d04827a92d9c5b21506854",
      "6243cbd9c95e4623aaad3f4cd2c94350",
      "5b592ffac1a3476cb52c9e28e4a1c815",
      "12c702f541454560aa9484547995834f",
      "8d04c2f5555b4ae385fad417f7faf829",
      "91c987fe9e37434bafff869e52564e57",
      "0daf9a0c32c24e1b9e5b89ff9f624cdb",
      "b716c23526ec47a987153737ce72fe6b",
      "600de8d642f94c2ab6afdf6bf89b475f",
      "6f6c7b0db11d4c958aee4ccc5da2e97e",
      "978bf5b6be6a40428acdb0868e70d385",
      "95a40e299c834d00b51921f17a37bc95",
      "f354c62edd804c18bbe11bef04584919",
      "b54a2ad0639b4091ac70c642274851b4",
      "64a7019d24a94765beec31df411526e3",
      "f4bdc4ef2168438eb3ba63eaf0e3ac02",
      "fafcbc887b9d486f98d089d3c312b067",
      "54873d33c4994be08ce614a91b85c020",
      "5606675ab72d4d159aad33e1a35b0646"
     ]
    },
    "id": "q6zGw_-S8VXD",
    "outputId": "61cc257f-171b-4b5b-861c-d0cb9b223e63"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2026-01-02T15:46:13.206473Z",
     "iopub.status.busy": "2026-01-02T15:46:13.206329Z",
     "iopub.status.idle": "2026-01-02T15:46:13.208474Z",
     "shell.execute_reply": "2026-01-02T15:46:13.208032Z",
     "shell.execute_reply.started": "2026-01-02T15:46:13.206458Z"
    },
    "id": "zvhlVH_q8VXD",
    "outputId": "237d3cbc-b586-47cc-e728-9315ea9f7fa1"
   },
   "outputs": [],
   "source": [
    "# dataset[3][\"input_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T15:46:13.209106Z",
     "iopub.status.busy": "2026-01-02T15:46:13.208973Z",
     "iopub.status.idle": "2026-01-02T15:46:13.211437Z",
     "shell.execute_reply": "2026-01-02T15:46:13.211037Z",
     "shell.execute_reply.started": "2026-01-02T15:46:13.209093Z"
    },
    "id": "9DDOahxa8VXD"
   },
   "outputs": [],
   "source": [
    "def collator(data):\n",
    "    return dict((key, [d[key] for d in data]) for key in data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "execution": {
     "iopub.execute_input": "2026-01-02T15:46:13.211970Z",
     "iopub.status.busy": "2026-01-02T15:46:13.211841Z",
     "iopub.status.idle": "2026-01-02T15:46:15.311476Z",
     "shell.execute_reply": "2026-01-02T15:46:15.310135Z",
     "shell.execute_reply.started": "2026-01-02T15:46:13.211956Z"
    },
    "id": "ipbojnfT8VXE",
    "outputId": "d8c6809c-0163-4727-9c7e-d428ede8d717"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/autodl-tmp/commit_generative_reinforcement_learning/trl/trainer/ppo_trainer.py:193: FutureWarning: `PPOTrainer` is deprecated and will be removed in trl v0.12. Please use `PPOv2Trainer` instead.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Failed to detect the name of this notebook. You can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ppo_trainer = PPOTrainer(\n",
    "    config, policy, ref_policy, tokenizer, train_ds, data_collator=collator\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sEVW9RT88VXE"
   },
   "source": [
    "### Load BERT classifier\n",
    "We load a BERT classifier fine-tuned on the IMDB dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2026-01-02T15:46:15.311744Z",
     "iopub.status.idle": "2026-01-02T15:46:15.311917Z",
     "shell.execute_reply": "2026-01-02T15:46:15.311836Z",
     "shell.execute_reply.started": "2026-01-02T15:46:15.311828Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2026-01-02T15:46:15.312526Z",
     "iopub.status.idle": "2026-01-02T15:46:15.312701Z",
     "shell.execute_reply": "2026-01-02T15:46:15.312620Z",
     "shell.execute_reply.started": "2026-01-02T15:46:15.312612Z"
    },
    "id": "xz40568u8VXE"
   },
   "outputs": [],
   "source": [
    "if ppo_trainer.accelerator.num_processes == 1:\n",
    "    device = 0 if torch.cuda.is_available() else \"cpu\"  # to avoid a `pipeline` bug\n",
    "else:\n",
    "    device = ppo_trainer.accelerator.device\n",
    "commit_pipe = pipeline(\n",
    "    \"text-classification\", \"/root/autodl-tmp/CommitFit/notebooks/E-3-best(70%)/my_awesome_model/checkpoint-390\", device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4_uFLMuK8VXF"
   },
   "source": [
    "The model outputs are the logits for the negative and positive class. We will use the logits for positive class as a reward signal for the language model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2026-01-02T15:46:15.313104Z",
     "iopub.status.idle": "2026-01-02T15:46:15.313255Z",
     "shell.execute_reply": "2026-01-02T15:46:15.313185Z",
     "shell.execute_reply.started": "2026-01-02T15:46:15.313178Z"
    },
    "id": "p7sqZU1s8VXF"
   },
   "outputs": [],
   "source": [
    "text = \"Change hasException to hasThrowable--\"\n",
    "output = commit_pipe(text, **commit_pipe_kwargs)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2026-01-02T15:46:15.313790Z",
     "iopub.status.idle": "2026-01-02T15:46:15.313947Z",
     "shell.execute_reply": "2026-01-02T15:46:15.313875Z",
     "shell.execute_reply.started": "2026-01-02T15:46:15.313868Z"
    },
    "id": "QIkMHbBG8VXF"
   },
   "outputs": [],
   "source": [
    "text = \"Trying to extend the Scheduler interface according- to the comments at -19.--\"\n",
    "output = commit_pipe(text, **commit_pipe_kwargs)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2026-01-02T15:46:15.314248Z",
     "iopub.status.idle": "2026-01-02T15:46:15.314393Z",
     "shell.execute_reply": "2026-01-02T15:46:15.314327Z",
     "shell.execute_reply.started": "2026-01-02T15:46:15.314320Z"
    },
    "id": "5OWO5EgF8VXF"
   },
   "outputs": [],
   "source": [
    "text = \"RunAsync method for outputting multiple values--\"\n",
    "output = commit_pipe(text, **commit_pipe_kwargs)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o2lpkv6N8VXG"
   },
   "source": [
    "The resulting reward signal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2026-01-02T15:46:15.314748Z",
     "iopub.status.idle": "2026-01-02T15:46:15.314893Z",
     "shell.execute_reply": "2026-01-02T15:46:15.314826Z",
     "shell.execute_reply.started": "2026-01-02T15:46:15.314819Z"
    },
    "id": "GBEE0d_G8VXG"
   },
   "outputs": [],
   "source": [
    "def extract_pipe_output(outputs):\n",
    "    logits_dicts = []\n",
    "    for out in outputs:    # 每个样本\n",
    "        logits = {element[\"label\"]: element[\"score\"] for element in out}\n",
    "        logits_dicts.append(logits)\n",
    "    return logits_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2026-01-02T15:46:15.315205Z",
     "iopub.status.idle": "2026-01-02T15:46:15.315348Z",
     "shell.execute_reply": "2026-01-02T15:46:15.315281Z",
     "shell.execute_reply.started": "2026-01-02T15:46:15.315274Z"
    },
    "id": "PSdwzBAk8VXG"
   },
   "outputs": [],
   "source": [
    "output[1][\"score\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bFSSbdVV8VXG"
   },
   "source": [
    "### Control token dict\n",
    "We will append the control token at the beginning of each query to signal the model what the target sentiment is. Each control sequence consists of three tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2026-01-02T15:46:15.315805Z",
     "iopub.status.idle": "2026-01-02T15:46:15.315955Z",
     "shell.execute_reply": "2026-01-02T15:46:15.315886Z",
     "shell.execute_reply.started": "2026-01-02T15:46:15.315879Z"
    },
    "id": "obXQKGe28VXH"
   },
   "outputs": [],
   "source": [
    "# import torch\n",
    "# 定义控制标签\n",
    "ctrl_str = [\"[Adaptive]\", \"[Perfective]\", \"[Corrective]\"]\n",
    "\n",
    "# 自动选择设备（GPU 优先）\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 把 control string 编码成 token，用于 prepend 到输入\n",
    "ctrl_tokens = {\n",
    "    s: tokenizer.encode(s, return_tensors=\"pt\").squeeze().to(device)\n",
    "    for s in ctrl_str\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2026-01-02T15:46:15.316305Z",
     "iopub.status.idle": "2026-01-02T15:46:15.316451Z",
     "shell.execute_reply": "2026-01-02T15:46:15.316384Z",
     "shell.execute_reply.started": "2026-01-02T15:46:15.316378Z"
    },
    "id": "soSQSZBl8VXH"
   },
   "outputs": [],
   "source": [
    "ctrl_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uc5OYVy78VXH"
   },
   "source": [
    "### Reward function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2026-01-02T15:46:15.316743Z",
     "iopub.status.idle": "2026-01-02T15:46:15.316884Z",
     "shell.execute_reply": "2026-01-02T15:46:15.316819Z",
     "shell.execute_reply.started": "2026-01-02T15:46:15.316813Z"
    }
   },
   "outputs": [],
   "source": [
    "label_map = {\n",
    "    \"[Adaptive]\": \"LABEL_0\",\n",
    "    \"[Perfective]\": \"LABEL_1\",\n",
    "    \"[Corrective]\": \"LABEL_2\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2026-01-02T15:46:15.317267Z",
     "iopub.status.idle": "2026-01-02T15:46:15.317414Z",
     "shell.execute_reply": "2026-01-02T15:46:15.317343Z",
     "shell.execute_reply.started": "2026-01-02T15:46:15.317337Z"
    }
   },
   "outputs": [],
   "source": [
    "def language_quality_reward(text: str) -> float:\n",
    "    \"\"\"\n",
    "    Heuristic language quality reward.\n",
    "    Returns a scalar float (can be negative).\n",
    "    \"\"\"\n",
    "    if text is None:\n",
    "        return -0.5\n",
    "    text = text.strip()\n",
    "    if len(text) == 0:\n",
    "        return -0.5\n",
    "\n",
    "    # 1) 长度约束（过短通常是碎片）\n",
    "    if len(text.split()) < 5:\n",
    "        return -0.3\n",
    "\n",
    "    # 2) 禁止 URL / License / Copyright 等噪声\n",
    "    blacklist = [\"http\", \"www\", \"license\", \"copyright\", \"©\"]\n",
    "    low = text.lower()\n",
    "    if any(b in low for b in blacklist):\n",
    "        return -0.5\n",
    "\n",
    "    # 3) 简单句子结构奖励（首字母大写）\n",
    "    if text[0].isupper():\n",
    "        return 0.2\n",
    "\n",
    "    return 0.0\n",
    "\n",
    "\n",
    "def task_logit_to_reward(\n",
    "    logits,\n",
    "    tasks,\n",
    "    responses=None,\n",
    "    alpha: float = 1.0,   # 分类对齐 reward 权重\n",
    "    beta: float = 1.0,    # 语言质量 reward 权重\n",
    "):\n",
    "    \"\"\"\n",
    "    Combine classifier-alignment reward and language-quality reward.\n",
    "\n",
    "    Args:\n",
    "        logits: List[Dict]  每个样本分类输出，如 {\"LABEL_0\":0.1,\"LABEL_1\":0.7,...}\n",
    "        tasks:  List[str]   control token list，如 ['[Adaptive]', ...]\n",
    "        responses: List[str] 生成的文本（用于语言质量 reward）。可为 None（则只用分类 reward）\n",
    "        alpha: 分类 reward 权重\n",
    "        beta:  语言质量 reward 权重\n",
    "\n",
    "    Returns:\n",
    "        rewards: List[torch.Tensor] 每个样本一个标量 reward tensor\n",
    "    \"\"\"\n",
    "    rewards = []\n",
    "    use_lang = responses is not None\n",
    "\n",
    "    for i, (logit, task) in enumerate(zip(logits, tasks)):\n",
    "        mapped_task = label_map[task]  # e.g. \"[Adaptive]\" -> \"LABEL_0\"\n",
    "        if mapped_task not in logit:\n",
    "            raise ValueError(\n",
    "                f\"Unknown task {mapped_task}, must be one of {list(logit.keys())}\"\n",
    "            )\n",
    "\n",
    "        cls_r = float(logit[mapped_task])\n",
    "\n",
    "        lang_r = 0.0\n",
    "        if use_lang:\n",
    "            lang_r = float(language_quality_reward(responses[i]))\n",
    "\n",
    "        final_r = alpha * cls_r + beta * lang_r\n",
    "        rewards.append(torch.tensor(final_r))\n",
    "\n",
    "    return rewards\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "geqP6fM78VXH"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9WewjV5x8VXH"
   },
   "source": [
    "The following examples show the rewards for the cases where the classifier logit is 4, -4 and 0 for the three targets ['Adaptive','Perfective','Corrective']. The scaling is not perfect as it differs between neutral and the other two classes. This is something to further investigate in the future. Ideally, one would use the logit output for each class individually, but since there is no dedicated class for neutral this is a workaround."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2026-01-02T15:46:15.317664Z",
     "iopub.status.idle": "2026-01-02T15:46:15.317807Z",
     "shell.execute_reply": "2026-01-02T15:46:15.317738Z",
     "shell.execute_reply.started": "2026-01-02T15:46:15.317732Z"
    },
    "id": "31wjdN168VXI"
   },
   "outputs": [],
   "source": [
    "print(ctrl_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bzLg6tda8VXI"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7knjIK2Y8VXN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-ymmb5FL8VXN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HmfUpDYS8VXN"
   },
   "source": [
    "### Generation settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Eb5caeU9E9UJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2026-01-02T15:46:15.318090Z",
     "iopub.status.idle": "2026-01-02T15:46:15.318232Z",
     "shell.execute_reply": "2026-01-02T15:46:15.318168Z",
     "shell.execute_reply.started": "2026-01-02T15:46:15.318161Z"
    },
    "id": "YpDvF69j8VXN"
   },
   "outputs": [],
   "source": [
    "generation_kwargs = {\n",
    "    \"min_length\": 1,   # -1 会报错，改成 1 或 0\n",
    "    \"top_k\": 0,        # 设为 0 表示不启用 top-k\n",
    "    \"top_p\": 1.0,\n",
    "    \"do_sample\": True,\n",
    "    \"pad_token_id\": tokenizer.eos_token_id,\n",
    "    \"max_new_tokens\": txt_out_len,\n",
    "    \"eos_token_id\": tokenizer.eos_token_id,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HzhEfok78VXN"
   },
   "source": [
    "## Optimize model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G0mUFSeS8VXN"
   },
   "source": [
    "**Steps**\n",
    "\n",
    "The training loop consists of the following steps:\n",
    "1. Get a batch of queries and create random controls\n",
    "2. Get the query responses from the policy\n",
    "3. Join query and responses and tokenize for BERT analysis\n",
    "4. Get sentiments for query/responses from BERT\n",
    "5. Optimize policy with PPO using the (query, response, reward) triplet\n",
    "6. Log all the training statistics\n",
    "\n",
    "**Training time**\n",
    "\n",
    "This step takes **~2h** on a P6000 GPU with the above specified settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2026-01-02T15:46:15.318616Z",
     "iopub.status.idle": "2026-01-02T15:46:15.318755Z",
     "shell.execute_reply": "2026-01-02T15:46:15.318691Z",
     "shell.execute_reply.started": "2026-01-02T15:46:15.318684Z"
    }
   },
   "outputs": [],
   "source": [
    "TASK2LABEL = {\n",
    "    \"[Corrective]\": \"LABEL_2\",\n",
    "    \"[SomeTask]\": \"LABEL_1\",\n",
    "    \"[Another]\": \"LABEL_0\",\n",
    "}\n",
    "\n",
    "LABEL2ID = {\"LABEL_0\": 0, \"LABEL_1\": 1, \"LABEL_2\": 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2026-01-02T15:46:15.319111Z",
     "iopub.status.idle": "2026-01-02T15:46:15.319252Z",
     "shell.execute_reply": "2026-01-02T15:46:15.319187Z",
     "shell.execute_reply.started": "2026-01-02T15:46:15.319180Z"
    },
    "id": "pe0_Bx5G8VXO"
   },
   "outputs": [],
   "source": [
    "for epoch in range(10):\n",
    "    for batch in tqdm(ppo_trainer.dataloader):\n",
    "        (\n",
    "            logs,\n",
    "            game_data,\n",
    "        ) = (\n",
    "            dict(),\n",
    "            dict(),\n",
    "        )\n",
    "\n",
    "        #### prepend a random control token\n",
    "        task_list = choices(ctrl_str, k=config.batch_size)\n",
    "        # print(task_list)\n",
    "        game_data[\"query\"] = [t + q for t, q in zip(task_list, batch[\"query\"])]\n",
    "        query_tensors = [\n",
    "            torch.cat((ctrl_tokens[t], input_ids))\n",
    "            for t, input_ids in zip(task_list, batch[\"input_ids\"])\n",
    "        ]\n",
    "\n",
    "        #### get response from gpt2\n",
    "        response_tensors = []\n",
    "        for query in query_tensors:\n",
    "            response = ppo_trainer.generate(query, **generation_kwargs)\n",
    "            response_tensors.append(response.squeeze())\n",
    "            # print(response)\n",
    "        game_data[\"response\"] = [\n",
    "            tokenizer.decode(r.squeeze(), skip_special_tokens=True, clean_up_tokenization_spaces=True,) for r in response_tensors\n",
    "        ]\n",
    "        \n",
    "        #### commit analysis\n",
    "        texts = [r for q, r in zip(batch[\"query\"], game_data[\"response\"])]\n",
    "        # print(texts)\n",
    "        logits = extract_pipe_output(commit_pipe(texts, **commit_pipe_kwargs))\n",
    "        # print(task_list)\n",
    "        rewards = task_logit_to_reward(\n",
    "            logits,\n",
    "            task_list,\n",
    "            responses=game_data[\"response\"],  # ⭐ 用生成文本算语言质量 reward\n",
    "            alpha=1.0,  # 分类对齐\n",
    "            beta=1.0,   # 语言质量（建议先从 0.5~1.0 试）\n",
    "        )\n",
    "        # print(rewards)\n",
    "        #### Run PPO training\n",
    "        t = time.time()\n",
    "        stats = ppo_trainer.step(query_tensors, response_tensors, rewards)\n",
    "        # print(stats)\n",
    "        for cs in ctrl_str:\n",
    "            key = \"env/reward_\" + cs.strip(\"[]\")\n",
    "            stats[key] = np.mean(\n",
    "                [r.cpu().numpy() for r, t in zip(rewards, task_list) if t == cs]\n",
    "            )\n",
    "        ppo_trainer.log_stats(stats, game_data, rewards)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k_lVXTTu8VXO"
   },
   "source": [
    "### Training progress\n",
    "If you are tracking the training progress with Weights&Biases you should see a plot similar to the following:\n",
    "\n",
    "<div style=\"text-align: center\">\n",
    "<img src='https://huggingface.co/datasets/trl-internal-testing/example-images/resolve/main/images/gpt2-ctrl-training-stats.png' width='800'>\n",
    "<p style=\"text-align: center;\"> <b>Figure:</b> Reward mean and distribution evolution during training. </p>\n",
    "</div>\n",
    "\n",
    "One can observe how the model starts to generate more positive outputs after a few optimisation steps.\n",
    "\n",
    "> Note: Investigating the KL-divergence will probably show that at this point the model has not converged to the target KL-divergence, yet. To get there would require longer training or starting with a higher initial coefficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2-xkwvlT8VXO"
   },
   "source": [
    "## Model inspection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zfXxbiqY8VXO"
   },
   "source": [
    "### Reward distribution\n",
    "First, we can have a look at the reward distribution. Both the negative and positive rewards are clearly shifted to high rewards. The neutral rewards, however, are still centered around zero. There are a few possible explanations for this. There could be a bug in the code and the way the neutral rewards are calculated. Another problem could be that sentence sometimes start with a strong sentiment and it is hard for the model shift the sentiment towards neutral."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2026-01-02T15:46:15.319525Z",
     "iopub.status.idle": "2026-01-02T15:46:15.319662Z",
     "shell.execute_reply": "2026-01-02T15:46:15.319600Z",
     "shell.execute_reply.started": "2026-01-02T15:46:15.319593Z"
    }
   },
   "outputs": [],
   "source": [
    "# stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2026-01-02T15:46:15.319933Z",
     "iopub.status.idle": "2026-01-02T15:46:15.320072Z",
     "shell.execute_reply": "2026-01-02T15:46:15.320004Z",
     "shell.execute_reply.started": "2026-01-02T15:46:15.319998Z"
    },
    "id": "SfgAeTat8VXO"
   },
   "outputs": [],
   "source": [
    "for ctrl_s in ctrl_str:\n",
    "    vals = [\n",
    "        r.item()\n",
    "        for r, t in zip(rewards, task_list)\n",
    "        if t == ctrl_s\n",
    "    ]\n",
    "    if len(vals) > 0:\n",
    "        plt.hist(\n",
    "            vals,\n",
    "            bins=20,\n",
    "            density=True,\n",
    "            alpha=0.5,\n",
    "            label=ctrl_s,\n",
    "        )\n",
    "\n",
    "plt.legend(loc=\"best\")\n",
    "plt.title(\"Reward Distribution (per control token)\")\n",
    "plt.xlabel(\"Reward\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ECDhclOz8VXO"
   },
   "source": [
    "## Save model\n",
    "Finally, we save the model to disk for later usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2026-01-02T15:46:15.320355Z",
     "iopub.status.idle": "2026-01-02T15:46:15.320492Z",
     "shell.execute_reply": "2026-01-02T15:46:15.320429Z",
     "shell.execute_reply.started": "2026-01-02T15:46:15.320423Z"
    },
    "id": "35nDpc2_8VXO"
   },
   "outputs": [],
   "source": [
    "policy.save_pretrained(\"codet5-msgs-ctrl\")\n",
    "tokenizer.save_pretrained(\"codet5-msgs-ctrl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2026-01-02T15:46:15.320850Z",
     "iopub.status.idle": "2026-01-02T15:46:15.320988Z",
     "shell.execute_reply": "2026-01-02T15:46:15.320924Z",
     "shell.execute_reply.started": "2026-01-02T15:46:15.320918Z"
    },
    "id": "dIiU9wSj8mRR"
   },
   "outputs": [],
   "source": [
    "#发送多种类型的邮件\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "import smtplib\n",
    "\n",
    "from email.mime.text import MIMEText\n",
    "msg_from = '915803745@qq.com'  # 发送方邮箱\n",
    "passwd = 'vcuosuurrgkfbdai'   #就是上面的授权码\n",
    " \n",
    "# to= ['g.zhang@gotion.com', 'j.tong@gotion.com'] #接受方邮箱\n",
    "to= ['j.tong@gotion.com'] #接受方邮箱\n",
    "#设置邮件内容\n",
    "#MIMEMultipart类可以放任何内容\n",
    "msg = MIMEMultipart()\n",
    "conntent=f\"{'成功'}\"\n",
    "#把内容加进去\n",
    "msg.attach(MIMEText(conntent,'plain','utf-8'))\n",
    " \n",
    "#设置邮件主题\n",
    "msg['Subject']=\"PPO学习模型训练完毕\"\n",
    " \n",
    "#发送方信息\n",
    "msg['From']=msg_from\n",
    " \n",
    "#开始发送\n",
    " \n",
    "#通过SSL方式发送，服务器地址和端口\n",
    "s = smtplib.SMTP_SSL(\"smtp.qq.com\", 465)\n",
    "# 登录邮箱\n",
    "s.login(msg_from, passwd)\n",
    "#开始发送\n",
    "s.sendmail(msg_from,to,msg.as_string())\n",
    "print(\"强化学习模型训练完毕\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
