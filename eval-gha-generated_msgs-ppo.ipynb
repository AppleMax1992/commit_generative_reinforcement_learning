{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f82a8cc-7b02-48d7-a783-6e89bccff8b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T00:38:29.995642Z",
     "iopub.status.busy": "2026-01-08T00:38:29.995084Z",
     "iopub.status.idle": "2026-01-08T00:38:37.803620Z",
     "shell.execute_reply": "2026-01-08T00:38:37.802744Z",
     "shell.execute_reply.started": "2026-01-08T00:38:29.995585Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-08 08:38:36.017659: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2026-01-08 08:38:36.075119: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2026-01-08 08:38:37.237847: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "/root/miniconda3/lib/python3.12/site-packages/keras/src/export/tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(np, \"object\"):\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/root/autodl-tmp/CommitFit')\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import ensemble_model.preprocesser as preprocesser \n",
    "import ensemble_model.combined_model as cm \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertModel, BertTokenizer, RobertaModel, RobertaTokenizer\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720f30c7-eecd-446e-918d-74122b4f79d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "666cb7bc-ce61-42cb-b7fa-934b5e5d3580",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T00:38:37.804608Z",
     "iopub.status.busy": "2026-01-08T00:38:37.804279Z",
     "iopub.status.idle": "2026-01-08T00:38:37.887899Z",
     "shell.execute_reply": "2026-01-08T00:38:37.887167Z",
     "shell.execute_reply.started": "2026-01-08T00:38:37.804589Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>repo</th>\n",
       "      <th>commit</th>\n",
       "      <th>labels</th>\n",
       "      <th>target_text</th>\n",
       "      <th>diffs</th>\n",
       "      <th>feature</th>\n",
       "      <th>diff_compact</th>\n",
       "      <th>source_text</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>apache</td>\n",
       "      <td>hadoop</td>\n",
       "      <td>06d24042b64d6fa0e179b5845990068f849d9ce5</td>\n",
       "      <td>1</td>\n",
       "      <td>YARN-1185. Fixed FileSystemRMStateStore to not...</td>\n",
       "      <td>diff --git a/hadoop-yarn-project/CHANGES.txt b...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 5, 156, 86, 5, 44, 0, 0,...</td>\n",
       "      <td>diff --git a/hadoop-yarn-project/CHANGES.txt b...</td>\n",
       "      <td>Write a concise Git commit message (imperative...</td>\n",
       "      <td>YARN-1185. Fixed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>apache</td>\n",
       "      <td>hbase</td>\n",
       "      <td>b246e68435e8d86a2a12fb8fe6c5aa9d9896ff92</td>\n",
       "      <td>2</td>\n",
       "      <td>HBASE-5259 Normalize the RegionLocation in- Ta...</td>\n",
       "      <td>diff --git a/src/main/java/org/apache/hadoop/h...</td>\n",
       "      <td>[1, 30, 0, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>diff --git a/src/main/java/org/apache/hadoop/h...</td>\n",
       "      <td>Write a concise Git commit message (imperative...</td>\n",
       "      <td>HBASE-919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GNOME</td>\n",
       "      <td>valadoc</td>\n",
       "      <td>ca2ba9131b10c5927172505f89f79cc0088dca3f</td>\n",
       "      <td>0</td>\n",
       "      <td>libvaladoc: gir-reader: improve short descs\\n</td>\n",
       "      <td>diff --git a/src/libvaladoc/content/blockconte...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>diff --git a/src/libvaladoc/content/blockconte...</td>\n",
       "      <td>Write a concise Git commit message (imperative...</td>\n",
       "      <td>libvaladoc: Add support for empty blocks\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>arquillian</td>\n",
       "      <td>arquillian-graphene</td>\n",
       "      <td>2ce3373d1db087a001b226bccfba43285246a1d4</td>\n",
       "      <td>0</td>\n",
       "      <td>chrome support added, when the browser is *chr...</td>\n",
       "      <td>diff --git a/api/src/main/java/org/jboss/arqui...</td>\n",
       "      <td>[6, 28, 13, 1, 20, 27, 1, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>diff --git a/api/src/main/java/org/jboss/arqui...</td>\n",
       "      <td>Write a concise Git commit message (imperative...</td>\n",
       "      <td>arquillian: add support for Selenium network t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>apache</td>\n",
       "      <td>hadoop</td>\n",
       "      <td>a3ecc3b910aa3bbc3ede2b8ba1bd040d02a26ca8</td>\n",
       "      <td>0</td>\n",
       "      <td>HDFS-4733. Make HttpFS username pattern- confi...</td>\n",
       "      <td>diff --git a/hadoop-hdfs-project/hadoop-hdfs-h...</td>\n",
       "      <td>[3, 12, 0, 6, 0, 0, 0, 2, 76, 4, 3, 17, 0, 0, ...</td>\n",
       "      <td>diff --git a/hadoop-hdfs-project/hadoop-hdfs-h...</td>\n",
       "      <td>Write a concise Git commit message (imperative...</td>\n",
       "      <td>Add support for user groups--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>kiegroup</td>\n",
       "      <td>drools</td>\n",
       "      <td>8b9ffeb5f2883e3d5187ad2f4a3a35540ff70326</td>\n",
       "      <td>1</td>\n",
       "      <td>JBRULES-527: fixing compilation problems--git-...</td>\n",
       "      <td>diff --git a/drools-core/src/main/java/org/dro...</td>\n",
       "      <td>[3, 28, 6, 15, 0, 50, 2, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>diff --git a/drools-core/src/main/java/org/dro...</td>\n",
       "      <td>Write a concise Git commit message (imperative...</td>\n",
       "      <td>Added support for indexed constraints--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>apache</td>\n",
       "      <td>hadoop</td>\n",
       "      <td>ed77c8925d7126f9ea3c8d9cbb1e246ad61ce37c</td>\n",
       "      <td>1</td>\n",
       "      <td>YARN-596. Use scheduling policies throughout t...</td>\n",
       "      <td>diff --git a/hadoop-yarn-project/CHANGES.txt b...</td>\n",
       "      <td>[11, 131, 38, 16, 28, 2, 8, 3, 35, 29, 42, 6, ...</td>\n",
       "      <td>diff --git a/hadoop-yarn-project/CHANGES.txt b...</td>\n",
       "      <td>Write a concise Git commit message (imperative...</td>\n",
       "      <td>YARN-596. Use scheduling policies throughout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>apache</td>\n",
       "      <td>deltaspike</td>\n",
       "      <td>4600b51887de35647220ca47fa1a09042db2cb52</td>\n",
       "      <td>1</td>\n",
       "      <td>DELTASPIKE-286 Comparators should be Serializa...</td>\n",
       "      <td>diff --git a/deltaspike/core/api/src/main/java...</td>\n",
       "      <td>[1, 6, 7, 10, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>diff --git a/deltaspike/core/api/src/main/java...</td>\n",
       "      <td>Write a concise Git commit message (imperative...</td>\n",
       "      <td>added support for annotated methods\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>kiegroup</td>\n",
       "      <td>drools</td>\n",
       "      <td>d51eaf7a642b4b4572aa9628e66b760e5c3ee2d5</td>\n",
       "      <td>1</td>\n",
       "      <td>JBRULES-1102 Bug in DefaultBetaConstraint clas...</td>\n",
       "      <td>diff --git a/drools-core/src/main/java/org/dro...</td>\n",
       "      <td>[5, 40, 2, 4, 1, 0, 0, 1, 246, 0, 0, 3, 0, 0, ...</td>\n",
       "      <td>diff --git a/drools-core/src/main/java/org/dro...</td>\n",
       "      <td>Write a concise Git commit message (imperative...</td>\n",
       "      <td>Added support for indexed fields--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>JetBrains</td>\n",
       "      <td>kotlin</td>\n",
       "      <td>f8a5c25714f866a85290634e7b0344f02f6b930b</td>\n",
       "      <td>1</td>\n",
       "      <td>Fix for the code to compile--</td>\n",
       "      <td>diff --git a/idea/src/org/jetbrains/jet/lang/c...</td>\n",
       "      <td>[4, 22, 18, 17, 4, 0, 0, 4, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>diff --git a/idea/src/org/jetbrains/jet/lang/c...</td>\n",
       "      <td>Write a concise Git commit message (imperative...</td>\n",
       "      <td>Added support for parent labels--</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>268 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           user                 repo  \\\n",
       "0        apache               hadoop   \n",
       "1        apache                hbase   \n",
       "2         GNOME              valadoc   \n",
       "3    arquillian  arquillian-graphene   \n",
       "4        apache               hadoop   \n",
       "..          ...                  ...   \n",
       "263    kiegroup               drools   \n",
       "264      apache               hadoop   \n",
       "265      apache           deltaspike   \n",
       "266    kiegroup               drools   \n",
       "267   JetBrains               kotlin   \n",
       "\n",
       "                                       commit  labels  \\\n",
       "0    06d24042b64d6fa0e179b5845990068f849d9ce5       1   \n",
       "1    b246e68435e8d86a2a12fb8fe6c5aa9d9896ff92       2   \n",
       "2    ca2ba9131b10c5927172505f89f79cc0088dca3f       0   \n",
       "3    2ce3373d1db087a001b226bccfba43285246a1d4       0   \n",
       "4    a3ecc3b910aa3bbc3ede2b8ba1bd040d02a26ca8       0   \n",
       "..                                        ...     ...   \n",
       "263  8b9ffeb5f2883e3d5187ad2f4a3a35540ff70326       1   \n",
       "264  ed77c8925d7126f9ea3c8d9cbb1e246ad61ce37c       1   \n",
       "265  4600b51887de35647220ca47fa1a09042db2cb52       1   \n",
       "266  d51eaf7a642b4b4572aa9628e66b760e5c3ee2d5       1   \n",
       "267  f8a5c25714f866a85290634e7b0344f02f6b930b       1   \n",
       "\n",
       "                                           target_text  \\\n",
       "0    YARN-1185. Fixed FileSystemRMStateStore to not...   \n",
       "1    HBASE-5259 Normalize the RegionLocation in- Ta...   \n",
       "2        libvaladoc: gir-reader: improve short descs\\n   \n",
       "3    chrome support added, when the browser is *chr...   \n",
       "4    HDFS-4733. Make HttpFS username pattern- confi...   \n",
       "..                                                 ...   \n",
       "263  JBRULES-527: fixing compilation problems--git-...   \n",
       "264  YARN-596. Use scheduling policies throughout t...   \n",
       "265  DELTASPIKE-286 Comparators should be Serializa...   \n",
       "266  JBRULES-1102 Bug in DefaultBetaConstraint clas...   \n",
       "267                      Fix for the code to compile--   \n",
       "\n",
       "                                                 diffs  \\\n",
       "0    diff --git a/hadoop-yarn-project/CHANGES.txt b...   \n",
       "1    diff --git a/src/main/java/org/apache/hadoop/h...   \n",
       "2    diff --git a/src/libvaladoc/content/blockconte...   \n",
       "3    diff --git a/api/src/main/java/org/jboss/arqui...   \n",
       "4    diff --git a/hadoop-hdfs-project/hadoop-hdfs-h...   \n",
       "..                                                 ...   \n",
       "263  diff --git a/drools-core/src/main/java/org/dro...   \n",
       "264  diff --git a/hadoop-yarn-project/CHANGES.txt b...   \n",
       "265  diff --git a/deltaspike/core/api/src/main/java...   \n",
       "266  diff --git a/drools-core/src/main/java/org/dro...   \n",
       "267  diff --git a/idea/src/org/jetbrains/jet/lang/c...   \n",
       "\n",
       "                                               feature  \\\n",
       "0    [0, 0, 0, 0, 0, 0, 0, 5, 156, 86, 5, 44, 0, 0,...   \n",
       "1    [1, 30, 0, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "2    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3    [6, 28, 13, 1, 20, 27, 1, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "4    [3, 12, 0, 6, 0, 0, 0, 2, 76, 4, 3, 17, 0, 0, ...   \n",
       "..                                                 ...   \n",
       "263  [3, 28, 6, 15, 0, 50, 2, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "264  [11, 131, 38, 16, 28, 2, 8, 3, 35, 29, 42, 6, ...   \n",
       "265  [1, 6, 7, 10, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "266  [5, 40, 2, 4, 1, 0, 0, 1, 246, 0, 0, 3, 0, 0, ...   \n",
       "267  [4, 22, 18, 17, 4, 0, 0, 4, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                          diff_compact  \\\n",
       "0    diff --git a/hadoop-yarn-project/CHANGES.txt b...   \n",
       "1    diff --git a/src/main/java/org/apache/hadoop/h...   \n",
       "2    diff --git a/src/libvaladoc/content/blockconte...   \n",
       "3    diff --git a/api/src/main/java/org/jboss/arqui...   \n",
       "4    diff --git a/hadoop-hdfs-project/hadoop-hdfs-h...   \n",
       "..                                                 ...   \n",
       "263  diff --git a/drools-core/src/main/java/org/dro...   \n",
       "264  diff --git a/hadoop-yarn-project/CHANGES.txt b...   \n",
       "265  diff --git a/deltaspike/core/api/src/main/java...   \n",
       "266  diff --git a/drools-core/src/main/java/org/dro...   \n",
       "267  diff --git a/idea/src/org/jetbrains/jet/lang/c...   \n",
       "\n",
       "                                           source_text  \\\n",
       "0    Write a concise Git commit message (imperative...   \n",
       "1    Write a concise Git commit message (imperative...   \n",
       "2    Write a concise Git commit message (imperative...   \n",
       "3    Write a concise Git commit message (imperative...   \n",
       "4    Write a concise Git commit message (imperative...   \n",
       "..                                                 ...   \n",
       "263  Write a concise Git commit message (imperative...   \n",
       "264  Write a concise Git commit message (imperative...   \n",
       "265  Write a concise Git commit message (imperative...   \n",
       "266  Write a concise Git commit message (imperative...   \n",
       "267  Write a concise Git commit message (imperative...   \n",
       "\n",
       "                                                  pred  \n",
       "0                                     YARN-1185. Fixed  \n",
       "1                                            HBASE-919  \n",
       "2           libvaladoc: Add support for empty blocks\\n  \n",
       "3    arquillian: add support for Selenium network t...  \n",
       "4                        Add support for user groups--  \n",
       "..                                                 ...  \n",
       "263            Added support for indexed constraints--  \n",
       "264       YARN-596. Use scheduling policies throughout  \n",
       "265              added support for annotated methods\\n  \n",
       "266                 Added support for indexed fields--  \n",
       "267                  Added support for parent labels--  \n",
       "\n",
       "[268 rows x 10 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =========================\n",
    "# 0) 配置\n",
    "# =========================\n",
    "CSV_PATH = \"/root/autodl-tmp/CommitFit/dataset/generated_commits-ppo.csv\"\n",
    "\n",
    "# =========================\n",
    "# 2) 读 CSV -> Dataset -> split\n",
    "# =========================\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "label2id={'Adaptive':0, 'Corrective':1, 'Perfective':2}\n",
    "df = df.replace({\"labels\": label2id})\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18e5ba2e-9175-4455-a42a-ced130563441",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T00:38:37.888602Z",
     "iopub.status.busy": "2026-01-08T00:38:37.888444Z",
     "iopub.status.idle": "2026-01-08T00:38:37.894110Z",
     "shell.execute_reply": "2026-01-08T00:38:37.893411Z",
     "shell.execute_reply.started": "2026-01-08T00:38:37.888586Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                       YARN-1185. Fixed\n",
       "1                                              HBASE-919\n",
       "2             libvaladoc: Add support for empty blocks\\n\n",
       "3      arquillian: add support for Selenium network t...\n",
       "4                          Add support for user groups--\n",
       "                             ...                        \n",
       "263              Added support for indexed constraints--\n",
       "264         YARN-596. Use scheduling policies throughout\n",
       "265                added support for annotated methods\\n\n",
       "266                   Added support for indexed fields--\n",
       "267                    Added support for parent labels--\n",
       "Name: pred, Length: 268, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = df\n",
    "test['pred']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ded5b2-b057-4117-b99b-fa77a39bb480",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b104969-4a01-44b3-8b11-72188d0042e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T00:38:37.894698Z",
     "iopub.status.busy": "2026-01-08T00:38:37.894547Z",
     "iopub.status.idle": "2026-01-08T00:38:37.897795Z",
     "shell.execute_reply": "2026-01-08T00:38:37.897081Z",
     "shell.execute_reply.started": "2026-01-08T00:38:37.894682Z"
    }
   },
   "outputs": [],
   "source": [
    "# train = train.groupby(\"label\", group_keys=False).apply(lambda x: x.sample(n=10, random_state=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b77e6e8-8d9d-45f3-be04-94a8b7499213",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T00:38:37.898478Z",
     "iopub.status.busy": "2026-01-08T00:38:37.898350Z",
     "iopub.status.idle": "2026-01-08T00:38:39.120288Z",
     "shell.execute_reply": "2026-01-08T00:38:39.119441Z",
     "shell.execute_reply.started": "2026-01-08T00:38:37.898465Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load BERT and CodeBERT models and tokenizers\n",
    "bert_model = BertModel.from_pretrained('/root/autodl-tmp/models/google-bert/bert-base-uncased')\n",
    "bert_tokenizer = BertTokenizer.from_pretrained('/root/autodl-tmp/models/google-bert/bert-base-uncased')\n",
    "\n",
    "codebert_model = RobertaModel.from_pretrained('/root/autodl-tmp/models/codebert-base')\n",
    "codebert_tokenizer = RobertaTokenizer.from_pretrained('/root/autodl-tmp/models/codebert-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754df1cb-3f7e-4ef8-974c-8f816fa5c88d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1549be02-6f6b-41e5-bd04-d3e164061eec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T00:38:39.121896Z",
     "iopub.status.busy": "2026-01-08T00:38:39.121713Z",
     "iopub.status.idle": "2026-01-08T00:38:40.871700Z",
     "shell.execute_reply": "2026-01-08T00:38:40.870928Z",
     "shell.execute_reply.started": "2026-01-08T00:38:39.121879Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CombinedModel(\n",
       "  (base_model1): BaseModel(\n",
       "    (transformer_model): BertModel(\n",
       "      (embeddings): BertEmbeddings(\n",
       "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "        (position_embeddings): Embedding(512, 768)\n",
       "        (token_type_embeddings): Embedding(2, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): BertEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0-11): 12 x BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSdpaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pooler): BertPooler(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (activation): Tanh()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (base_model2): BaseModel(\n",
       "    (transformer_model): RobertaModel(\n",
       "      (embeddings): RobertaEmbeddings(\n",
       "        (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "        (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "        (token_type_embeddings): Embedding(1, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): RobertaEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0-11): 12 x RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSdpaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pooler): RobertaPooler(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (activation): Tanh()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): Linear(in_features=1536, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Create Datasets and DataLoaders\n",
    "# train_dataset = preprocesser.SentencePairDataset(train, bert_tokenizer, codebert_tokenizer,message='msgs',command='diff_compact',label='labels')\n",
    "# val_dataset = preprocesser.SentencePairDataset(val, bert_tokenizer, codebert_tokenizer,message='msgs',command='diff_compact',label='labels')\n",
    "test_dataset = preprocesser.SentencePairDataset(test, bert_tokenizer, codebert_tokenizer,message='pred',command='diff_compact',label='labels')\n",
    "# train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "# val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "# 自动选择设备（GPU 优先）\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Load BERT and CodeBERT models and tokenizers\n",
    "bert_model = BertModel.from_pretrained('/root/autodl-tmp/models/google-bert/bert-base-uncased')\n",
    "bert_tokenizer = BertTokenizer.from_pretrained('/root/autodl-tmp/models/google-bert/bert-base-uncased')\n",
    "\n",
    "codebert_model = RobertaModel.from_pretrained('/root/autodl-tmp/models/codebert-base')\n",
    "codebert_tokenizer = RobertaTokenizer.from_pretrained('/root/autodl-tmp/models/codebert-base')\n",
    "\n",
    "# 加载\n",
    "ckpt = torch.load(\"/root/autodl-tmp/CommitFit/notebooks/E-3-best(70%)/reward_model_combined.pt\")\n",
    "# 重新构建结构（必须和训练时一致）\n",
    "base_model1 = cm.BaseModel(bert_model)\n",
    "base_model2 = cm.BaseModel(codebert_model)\n",
    "reward_model = cm.CombinedModel(\n",
    "    base_model1=base_model1,\n",
    "    base_model2=base_model2\n",
    "    # hidden_dim=???  如果你的 __init__ 需要，就得你自己传训练时的值\n",
    ").to(device)\n",
    "\n",
    "reward_model.load_state_dict(ckpt[\"model_state_dict\"])\n",
    "reward_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "def4bb0a-419c-46fb-b61b-c9f1a98f0caa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T00:38:40.872249Z",
     "iopub.status.busy": "2026-01-08T00:38:40.872079Z",
     "iopub.status.idle": "2026-01-08T00:38:40.882286Z",
     "shell.execute_reply": "2026-01-08T00:38:40.881251Z",
     "shell.execute_reply.started": "2026-01-08T00:38:40.872232Z"
    }
   },
   "outputs": [],
   "source": [
    "test_dataset = preprocesser.SentencePairDataset(test, bert_tokenizer, codebert_tokenizer,message='pred',command='diff_compact',label='labels')\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e01924f-b8a3-4282-acf6-6d38aee2620c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T00:38:40.882958Z",
     "iopub.status.busy": "2026-01-08T00:38:40.882780Z",
     "iopub.status.idle": "2026-01-08T00:38:40.889141Z",
     "shell.execute_reply": "2026-01-08T00:38:40.888395Z",
     "shell.execute_reply.started": "2026-01-08T00:38:40.882940Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      diff --git a/hadoop-yarn-project/CHANGES.txt b...\n",
       "1      diff --git a/src/main/java/org/apache/hadoop/h...\n",
       "2      diff --git a/src/libvaladoc/content/blockconte...\n",
       "3      diff --git a/api/src/main/java/org/jboss/arqui...\n",
       "4      diff --git a/hadoop-hdfs-project/hadoop-hdfs-h...\n",
       "                             ...                        \n",
       "263    diff --git a/drools-core/src/main/java/org/dro...\n",
       "264    diff --git a/hadoop-yarn-project/CHANGES.txt b...\n",
       "265    diff --git a/deltaspike/core/api/src/main/java...\n",
       "266    diff --git a/drools-core/src/main/java/org/dro...\n",
       "267    diff --git a/idea/src/org/jetbrains/jet/lang/c...\n",
       "Name: diff_compact, Length: 268, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['diff_compact']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92009384-7770-4b2a-97b2-c0b4d209a0a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ad177a-0ad0-414e-a5b6-5b768a5da9cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5878d2a3-fe90-45b1-9486-739c4fee6004",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T00:38:40.889838Z",
     "iopub.status.busy": "2026-01-08T00:38:40.889670Z",
     "iopub.status.idle": "2026-01-08T00:38:45.095223Z",
     "shell.execute_reply": "2026-01-08T00:38:45.094474Z",
     "shell.execute_reply.started": "2026-01-08T00:38:40.889821Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evaluate: 100%|██████████| 9/9 [00:04<00:00,  2.15batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5111940298507462\n",
      "Precision: 0.5492425826655198\n",
      "Recall: 0.5111940298507462\n",
      "F1-Score: 0.503357532757551\n"
     ]
    }
   ],
   "source": [
    "test_acc, test_labels, test_probabilities, test_embeddings, test_predictions = reward_model.evaluate(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0376c52a-7906-4b38-ab5b-88be13b3b3d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14393aa5-3ad7-4dae-953c-ff77d8005640",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T00:38:45.096168Z",
     "iopub.status.busy": "2026-01-08T00:38:45.095945Z",
     "iopub.status.idle": "2026-01-08T00:38:45.099101Z",
     "shell.execute_reply": "2026-01-08T00:38:45.098533Z",
     "shell.execute_reply.started": "2026-01-08T00:38:45.096147Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ee6becf-2511-478b-9487-d37f19cc708e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T00:38:45.099811Z",
     "iopub.status.busy": "2026-01-08T00:38:45.099628Z",
     "iopub.status.idle": "2026-01-08T00:38:45.106019Z",
     "shell.execute_reply": "2026-01-08T00:38:45.105276Z",
     "shell.execute_reply.started": "2026-01-08T00:38:45.099793Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[60,  8, 11],\n",
       "       [37, 39, 13],\n",
       "       [42, 20, 38]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = metrics.confusion_matrix(test_labels, test_predictions)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b84edf12-7846-4311-8539-7078f9801402",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T00:38:45.106546Z",
     "iopub.status.busy": "2026-01-08T00:38:45.106414Z",
     "iopub.status.idle": "2026-01-08T00:38:45.109079Z",
     "shell.execute_reply": "2026-01-08T00:38:45.108466Z",
     "shell.execute_reply.started": "2026-01-08T00:38:45.106533Z"
    }
   },
   "outputs": [],
   "source": [
    "# import torch\n",
    "# # 保存\n",
    "# torch.save(\n",
    "#     {\n",
    "#         \"model_state_dict\": combined_model.state_dict(),\n",
    "#         \"num_labels\": 3,\n",
    "#     },\n",
    "#     \"./reward_model_combined.pt\",\n",
    "# )\n",
    "\n",
    "# # 加载\n",
    "# ckpt = torch.load(\"reward_model_combined.pt\")\n",
    "# combined_model.load_state_dict(ckpt[\"model_state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d231095-873f-419b-accf-256577523d83",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T00:38:45.109626Z",
     "iopub.status.busy": "2026-01-08T00:38:45.109485Z",
     "iopub.status.idle": "2026-01-08T00:38:45.111811Z",
     "shell.execute_reply": "2026-01-08T00:38:45.111350Z",
     "shell.execute_reply.started": "2026-01-08T00:38:45.109612Z"
    }
   },
   "outputs": [],
   "source": [
    "# 加载\n",
    "# reward_model = torch.load(\"reward_model_combined.pth\")\n",
    "# combined_model.load_state_dict(ckpt[\"model_state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89e6f9cd-8d2c-4d7e-ae0e-46cee540777a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T00:38:45.112335Z",
     "iopub.status.busy": "2026-01-08T00:38:45.112191Z",
     "iopub.status.idle": "2026-01-08T00:38:46.264977Z",
     "shell.execute_reply": "2026-01-08T00:38:46.263164Z",
     "shell.execute_reply.started": "2026-01-08T00:38:45.112321Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "强化学习模型训练完毕\n"
     ]
    }
   ],
   "source": [
    "#发送多种类型的邮件\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "import smtplib\n",
    "\n",
    "from email.mime.text import MIMEText\n",
    "msg_from = '915803745@qq.com'  # 发送方邮箱\n",
    "passwd = 'vcuosuurrgkfbdai'   #就是上面的授权码\n",
    " \n",
    "# to= ['g.zhang@gotion.com', 'j.tong@gotion.com'] #接受方邮箱\n",
    "to= ['j.tong@gotion.com'] #接受方邮箱\n",
    "#设置邮件内容\n",
    "#MIMEMultipart类可以放任何内容\n",
    "msg = MIMEMultipart()\n",
    "conntent=f\"强化学习\"\n",
    "#把内容加进去\n",
    "msg.attach(MIMEText(conntent,'plain','utf-8'))\n",
    " \n",
    "#设置邮件主题\n",
    "msg['Subject']=\"强化学习模型训练完毕\"\n",
    " \n",
    "#发送方信息\n",
    "msg['From']=msg_from\n",
    " \n",
    "#开始发送\n",
    " \n",
    "#通过SSL方式发送，服务器地址和端口\n",
    "s = smtplib.SMTP_SSL(\"smtp.qq.com\", 465)\n",
    "# 登录邮箱\n",
    "s.login(msg_from, passwd)\n",
    "#开始发送\n",
    "s.sendmail(msg_from,to,msg.as_string())\n",
    "print(\"强化学习模型训练完毕\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3084ce4f-6970-4812-b9c1-f09f8207f2f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0cb527-8732-43b7-8e88-2e50a1b6de90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9248fb4-719c-423e-9f70-001fca1d5fb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3fa80c-6e0c-42a1-92d2-669cca1e84f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca9b990-a568-4acc-8194-53b47fc3452c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f84c3b-5e00-416b-88d8-b9e1b0b846d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad24f5e-d1c1-4d34-b7e9-43dc6efa7d37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
